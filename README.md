# ACM-FAT ML Resource Braindump

This repo consists of almost all the resources related to Fairness, Accountability &amp; Transparency in the Machine learning field. ( Everything that has been gathered here have been done so as a part of an independent study course ISM 6905.005 (Fall 2019) under the guidance of [Prof. Padmanabhan](https://www.usf.edu/business/contacts/padmanabhan-balaji.aspx)


## Table of Contents:
- [Papers](#papers)
- [People (involved in research in this field)](#people-involved-in-research-in-this-field)
- [Datasets](#datasets)
- [Code Repositories & Implementation details](#code-repositories--implementation-details)
- [Misc. resources](#miscellaneous-resources)


## Papers:
Below are a list of research papers that were finalized based on the number of citations references on the FAT ML topic.

- [Algorithmic bias: from discrimination discovery to fairness-aware data mining](http://chato.cl/research/files/tutorial-algorithmic-bias.pdf)
- [Discovering Unwarranted Associations in Data-Driven Applications with the FairTest Testing Toolkit](https://arxiv.org/pdf/1510.02377.pdf)
- [Survey of Approaches for Discrimination Prevention in Data Mining]()
- [Fairer machine learning in the real world: Mitigating discrimination without collecting sensitive data]()
- [ Visual Data Mining for Higher-level Patterns: Discrimination-Aware Data Mining and Beyond]()
- [Fairness-Aware Classifier with Prejudice Remover Regularizer]()
- [Three naive Bayes approaches for discrimination-free Classification]()
- [Classification with No Discrimination by Preferential Sampling]()
- [Rawlsian Fairness for Machine Learning]()
- [The Measure and Mismeasure of Fairness: A Critical Review of Fair Machine Learning]()
- [A Reductions Approach to Fair Classification]()
- [Fairness in Machine Learning: Lessons from Political Philosophy]()
- [Fairness Through Computationally-Bounded Awareness]()
- [ Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments]()
- [“Fair” Risk Assessments: A Precarious Approach for Criminal Justice Reform]()
- [Penalizing Unfairness in Binary Classification]()
- [The Case for Process Fairness in Learning: Feature Selection for Fair Decision Making]()
- [Fairer and more accurate, but for whom?]()
- [Auditing Black-box Models for Indirect Influence ]()
- [Impartial Predictive Modeling: Ensuring Fairness in Arbitrary Models]()
- [Fairness-aware Learning through Regularization Approach ]()
- [Is it ethical to avoid error analysis?]()
- [Discovering Unwarranted Associations in Data-Driven Applications with the FairTest Testing Toolkit ]()
- [Discriminatory Transfer]()
- [A data-driven software tool for enabling cooperative information sharing among police departments ]()
- [Equality of Opportunity in Supervised Learning]()
- [On the relation between accuracy and fairness in binary classification ]()
- [To predict and serve?]()
- [On Formalizing Fairness in Prediction with Machine Learning]()
- [InclusiveFaceNet: Improving Face Attribute Detection with Race and Gender Diversity]()
- [Datasheets for Datasets]()
- [A Framework for Understanding Unintended Consequences of Machine Learning]()
- [Towards Accountability: The Articulation and Formalization of Fairness in Machine Learning]()
- [Mathematical Notions vs. Human Perception of Fairness: A Descriptive Approach to Fairness for Machine Learning]()
- [FAIRNESS IN LEARNING: Classic and Contextual Bandits]()
- [Accuracy and Fairness for Juvenile Justice Risk Assessments]()
- [Group Fairness Under Composition]()
- [Algorithmic Decision Making and the Cost of Fairness]()
- [Fairness in Criminal Justice Risk Assessments: The State of the Art]()
- [Fairness constraints: Mechanisms for fair classification]()
- [Fairness testing: testing software for discrimination]()
- [Avoiding Discrimination through Causal Reasoning]()
- [Fairness-aware learning through regularization approach]()
- [On Fairness and Calibration]()
- [A Confidence-Based Approach for Balancing Fairness and Accuracy]()
- [Learning Fair Classifiers: A Regularization-Inspired Approach]()
- [Fair and Unbiased Algorithmic Decision Making: Current State and Future Challenges ]()
- [Fairness and Abstraction in Sociotechnical Systems]()
- [Mitigating Bias in Gender, Age and Ethnicity Classification: a Multi-Task Convolution Neural Network Approach]()
- [Women Also Snowboard: Overcoming Bias in Captioning Models]()
- [On the effect of age perception biases for real age regression]()
- [Fairness in Proprietary Image Tagging Algorithms: A Cross-Platform Audit on People Images]()
- [Case for process fairness in learning: ]()
- [Counterfactual Fairness]()
- [Learning Fair Representations:]()
- [Certifying and Removing Disparate Impact]()
- [Fairness and Accountability Design Needs for Algorithmic Support in High-Stakes Public Sector Decision-Making]()
- [Blind Justice: Fairness with Encrypted Sensitive Attributes]()
- [Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?]()
- [Semantics derived automatically from language corpora contain human-like biases]()



## People (involved in research in ACM FAT):


## Datasets:
Datasets that are provided below were finalized based on features, etc. that were intensive to FAT ML research.

## Code Repositories & Implementation details:
These consist of a list of repositories that were tested out on a dev box 


## Miscellaneous resources:
Links to related courses & articles.



