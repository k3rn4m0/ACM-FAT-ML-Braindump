# ACM-FAT ML Resource Braindump

This repo consists of almost all the resources related to Fairness, Accountability &amp; Transparency in the Machine learning field. ( Everything that has been gathered here have been done so as a part of an independent study course ISM 6905.005 (Fall 2019) under the guidance of [Prof. Padmanabhan](https://www.usf.edu/business/contacts/padmanabhan-balaji.aspx)


## Table of Contents:
- [Papers](#papers)
- [People (involved in research in this field)](#people-involved-in-research-in-acm-fat)
- [Datasets](#datasets)
- [Code Repositories & Implementation details](#code-repositories--implementation-details)
- [Misc. resources](#miscellaneous-resources)


## Papers:
Below are a list of research papers that were finalized based on the number of citations references on the FAT ML topic.

- [Algorithmic bias: from discrimination discovery to fairness-aware data mining](http://chato.cl/research/files/tutorial-algorithmic-bias.pdf)
- [Discovering Unwarranted Associations in Data-Driven Applications with the FairTest Testing Toolkit](https://arxiv.org/pdf/1510.02377.pdf)
- [Survey of Approaches for Discrimination Prevention in Data Mining](http://ijcsit.com/docs/Volume%205/vol5issue06/ijcsit20140506270.pdf)
- [Fairer machine learning in the real world: Mitigating discrimination without collecting sensitive data](https://journals.sagepub.com/doi/pdf/10.1177/2053951717743530)
- [Visual Data Mining for Higher-level Patterns: Discrimination-Aware Data Mining and Beyond](https://pdfs.semanticscholar.org/5be8/ddbc70e61884f3344cc75b825f68216e4939.pdf)
- [Fairness-Aware Classifier with Prejudice Remover Regularizer](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.297.566&rep=rep1&type=pdf)
- [Three naive Bayes approaches for discrimination-free Classification](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.422.9495&rep=rep1&type=pdf)
- [Classification with No Discrimination by Preferential Sampling](https://dtai.cs.kuleuven.be/events/Benelearn2010/submissions/benelearn2010_submission_18.pdf)
- [Rawlsian Fairness for Machine Learning](https://pdfs.semanticscholar.org/2d55/ff4542eaae18dcd10c2cd74199396e260402.pdf?_ga=2.220660369.842654541.1573764061-1597523580.1573764061)
- [The Measure and Mismeasure of Fairness: A Critical Review of Fair Machine Learning](https://5harad.com/papers/fair-ml.pdf)
- [A Reductions Approach to Fair Classification]()
- [Fairness in Machine Learning: Lessons from Political Philosophy]()
- [Fairness Through Computationally-Bounded Awareness]()
- [ Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments]()
- [“Fair” Risk Assessments: A Precarious Approach for Criminal Justice Reform]()
- [Penalizing Unfairness in Binary Classification]()
- [The Case for Process Fairness in Learning: Feature Selection for Fair Decision Making]()
- [Fairer and more accurate, but for whom?]()
- [Auditing Black-box Models for Indirect Influence ]()
- [Impartial Predictive Modeling: Ensuring Fairness in Arbitrary Models]()
- [Fairness-aware Learning through Regularization Approach ]()
- [Is it ethical to avoid error analysis?]()
- [Discovering Unwarranted Associations in Data-Driven Applications with the FairTest Testing Toolkit ]()
- [Discriminatory Transfer]()
- [A data-driven software tool for enabling cooperative information sharing among police departments ]()
- [Equality of Opportunity in Supervised Learning]()
- [On the relation between accuracy and fairness in binary classification ]()
- [To predict and serve?]()
- [On Formalizing Fairness in Prediction with Machine Learning]()
- [InclusiveFaceNet: Improving Face Attribute Detection with Race and Gender Diversity]()
- [Datasheets for Datasets]()
- [A Framework for Understanding Unintended Consequences of Machine Learning]()
- [Towards Accountability: The Articulation and Formalization of Fairness in Machine Learning]()
- [Mathematical Notions vs. Human Perception of Fairness: A Descriptive Approach to Fairness for Machine Learning]()
- [FAIRNESS IN LEARNING: Classic and Contextual Bandits]()
- [Accuracy and Fairness for Juvenile Justice Risk Assessments]()
- [Group Fairness Under Composition]()
- [Algorithmic Decision Making and the Cost of Fairness]()
- [Fairness in Criminal Justice Risk Assessments: The State of the Art]()
- [Fairness constraints: Mechanisms for fair classification]()
- [Fairness testing: testing software for discrimination]()
- [Avoiding Discrimination through Causal Reasoning]()
- [Fairness-aware learning through regularization approach]()
- [On Fairness and Calibration]()
- [A Confidence-Based Approach for Balancing Fairness and Accuracy]()
- [Learning Fair Classifiers: A Regularization-Inspired Approach](https://scinapse.io/papers/2732098159)
- [Fair and Unbiased Algorithmic Decision Making: Current State and Future Challenges ](https://arxiv.org/ftp/arxiv/papers/1901/1901.04730.pdf)
- [Fairness and Abstraction in Sociotechnical Systems](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3265913)
- [Mitigating Bias in Gender, Age and Ethnicity Classification: a Multi-Task Convolution Neural Network Approach](https://hal.inria.fr/hal-01892103/document)
- [Women Also Snowboard: Overcoming Bias in Captioning Models](http://openaccess.thecvf.com/content_ECCV_2018/papers/Lisa_Anne_Hendricks_Women_also_Snowboard_ECCV_2018_paper.pdf)
- [On the effect of age perception biases for real age regression](https://arxiv.org/pdf/1902.07653.pdf)
- [Fairness in Proprietary Image Tagging Algorithms: A Cross-Platform Audit on People Images](https://aaai.org/ojs/index.php/ICWSM/article/view/3232/3100)
- [Case for process fairness in learning: Feature Selection for Fair Decision Making](https://people.mpi-sws.org/~gummadi/papers/process_fairness.pdf)
- [Counterfactual Fairness](https://papers.nips.cc/paper/6995-counterfactual-fairness.pdf)
- [Learning Fair Representations:](https://www.cs.toronto.edu/~toni/Papers/icml-final.pdf)
- [Certifying and Removing Disparate Impact](https://arxiv.org/pdf/1412.3756.pdf)
- [Fairness and Accountability Design Needs for Algorithmic Support in High-Stakes Public Sector Decision-Making](https://arxiv.org/pdf/1802.01029.pdf)
- [Blind Justice: Fairness with Encrypted Sensitive Attributes](https://arxiv.org/pdf/1806.03281.pdf)
- [Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?](https://arxiv.org/pdf/1812.05239.pdf)
- [Semantics derived automatically from language corpora contain human-like biases](https://www.cs.bath.ac.uk/~jjb/ftp/CaliskanEtAl-authors-full.pdf)



## People (involved in research in ACM FAT):


## Datasets:
Datasets that are provided below were finalized based on features, etc. that were intensive to FAT ML research.

## Code Repositories & Implementation details:
These consist of a list of repositories that were tested out on a dev box 


## Miscellaneous resources:
Links to related courses & articles.



